<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Craby Voice Call ðŸ¦€</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      color: #fff;
      padding: 20px;
    }
    
    .container {
      max-width: 400px;
      width: 100%;
      text-align: center;
    }
    
    h1 { font-size: 2.5rem; margin-bottom: 10px; }
    .subtitle { color: #8892b0; margin-bottom: 30px; }
    
    .call-status {
      font-size: 1.2rem;
      margin-bottom: 20px;
      min-height: 30px;
    }
    
    .call-status.listening { color: #64ffda; }
    .call-status.speaking { color: #ffd93d; }
    .call-status.processing { color: #ff6b6b; }
    .call-status.playing { color: #a855f7; }
    
    .call-button {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      border: none;
      font-size: 2.5rem;
      cursor: pointer;
      transition: all 0.3s ease;
      margin: 20px auto;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    
    .call-button.inactive {
      background: linear-gradient(145deg, #27ae60, #2ecc71);
      box-shadow: 0 10px 30px rgba(46, 204, 113, 0.4);
    }
    
    .call-button.active {
      background: linear-gradient(145deg, #e74c3c, #c0392b);
      box-shadow: 0 10px 30px rgba(231, 76, 60, 0.4);
      animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.05); }
    }
    
    .visualizer {
      display: flex;
      justify-content: center;
      align-items: flex-end;
      height: 60px;
      gap: 4px;
      margin: 20px 0;
    }
    
    .bar {
      width: 8px;
      background: #64ffda;
      border-radius: 4px;
      transition: height 0.1s ease;
    }
    
    .transcript {
      background: rgba(255,255,255,0.05);
      border-radius: 15px;
      padding: 15px;
      margin-top: 20px;
      max-height: 200px;
      overflow-y: auto;
      text-align: left;
      font-size: 0.9rem;
    }
    
    .transcript p {
      margin: 8px 0;
      padding: 8px 12px;
      border-radius: 8px;
    }
    
    .transcript .you { background: rgba(100, 255, 218, 0.1); }
    .transcript .craby { background: rgba(168, 85, 247, 0.1); }
    
    .hint {
      color: #8892b0;
      font-size: 0.8rem;
      margin-top: 15px;
    }
    
    audio { display: none; }
  </style>
</head>
<body>
  <div class="container">
    <h1>ðŸ¦€ Craby</h1>
    <p class="subtitle">Voice Call</p>
    
    <div class="call-status" id="status">Tap to start call</div>
    
    <button class="call-button inactive" id="callBtn">ðŸ“ž</button>
    
    <div class="visualizer" id="visualizer">
      <div class="bar" style="height: 10px;"></div>
      <div class="bar" style="height: 10px;"></div>
      <div class="bar" style="height: 10px;"></div>
      <div class="bar" style="height: 10px;"></div>
      <div class="bar" style="height: 10px;"></div>
      <div class="bar" style="height: 10px;"></div>
      <div class="bar" style="height: 10px;"></div>
      <div class="bar" style="height: 10px;"></div>
    </div>
    
    <div class="transcript" id="transcript"></div>
    
    <p class="hint">Just talk naturally. Craby will respond when you pause.</p>
  </div>
  
  <audio id="audioPlayer"></audio>
  
  <script>
    const callBtn = document.getElementById('callBtn');
    const statusEl = document.getElementById('status');
    const transcriptEl = document.getElementById('transcript');
    const audioPlayer = document.getElementById('audioPlayer');
    const visualizer = document.getElementById('visualizer');
    const bars = visualizer.querySelectorAll('.bar');
    
    let ws;
    let isInCall = false;
    let mediaRecorder;
    let audioContext;
    let analyser;
    let stream;
    let silenceTimer;
    let isRecording = false;
    let audioChunks = [];
    let isPlaying = false;
    
    // Voice Activity Detection settings
    const SILENCE_THRESHOLD = 15; // Volume level considered silence
    const SILENCE_DURATION = 1500; // ms of silence before sending
    const MIN_RECORDING_TIME = 500; // Minimum recording time in ms
    
    function setStatus(text, className) {
      statusEl.textContent = text;
      statusEl.className = 'call-status ' + (className || '');
    }
    
    function addTranscript(who, text) {
      const p = document.createElement('p');
      p.className = who.toLowerCase();
      p.textContent = `${who}: ${text}`;
      transcriptEl.appendChild(p);
      transcriptEl.scrollTop = transcriptEl.scrollHeight;
    }
    
    function updateVisualizer(volume) {
      bars.forEach((bar, i) => {
        const height = Math.max(10, Math.min(50, volume * (0.5 + Math.random() * 0.5)));
        bar.style.height = height + 'px';
        bar.style.background = isRecording ? '#64ffda' : (isPlaying ? '#a855f7' : '#4a5568');
      });
    }
    
    // Connect WebSocket
    function connect() {
      const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
      ws = new WebSocket(`${protocol}//${location.host}`);
      
      ws.onopen = () => console.log('Connected');
      
      ws.onclose = () => {
        console.log('Disconnected');
        if (isInCall) setTimeout(connect, 2000);
      };
      
      ws.onmessage = async (event) => {
        if (event.data instanceof Blob) {
          // Audio response - play it
          isPlaying = true;
          setStatus('Craby speaking...', 'playing');
          const audioUrl = URL.createObjectURL(event.data);
          audioPlayer.src = audioUrl;
          audioPlayer.play();
        } else {
          const msg = JSON.parse(event.data);
          if (msg.type === 'transcript') {
            addTranscript('You', msg.text);
          } else if (msg.type === 'response') {
            addTranscript('Craby', msg.text);
          } else if (msg.type === 'status') {
            setStatus(msg.message, 'processing');
          }
        }
      };
    }
    
    // Audio finished playing - start listening again
    audioPlayer.onended = () => {
      isPlaying = false;
      if (isInCall) {
        startListening();
      }
    };
    
    // Start the call
    async function startCall() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // Setup audio analysis for VAD
        audioContext = new AudioContext();
        analyser = audioContext.createAnalyser();
        const source = audioContext.createMediaStreamSource(stream);
        source.connect(analyser);
        analyser.fftSize = 256;
        
        // Setup media recorder
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
        
        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) audioChunks.push(e.data);
        };
        
        mediaRecorder.onstop = () => {
          if (audioChunks.length > 0 && isInCall) {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            ws.send(audioBlob);
            setStatus('Processing...', 'processing');
          }
          audioChunks = [];
        };
        
        isInCall = true;
        callBtn.className = 'call-button active';
        callBtn.textContent = 'ðŸ“µ';
        connect();
        
        startListening();
        
      } catch (err) {
        console.error('Mic error:', err);
        setStatus('Microphone access denied', '');
      }
    }
    
    // End the call
    function endCall() {
      isInCall = false;
      isRecording = false;
      
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (audioContext) {
        audioContext.close();
      }
      if (ws) {
        ws.close();
      }
      if (silenceTimer) {
        clearTimeout(silenceTimer);
      }
      
      callBtn.className = 'call-button inactive';
      callBtn.textContent = 'ðŸ“ž';
      setStatus('Call ended', '');
      updateVisualizer(0);
    }
    
    // Start listening for voice
    function startListening() {
      if (!isInCall || isPlaying) return;
      
      setStatus('Listening...', 'listening');
      isRecording = false;
      audioChunks = [];
      
      detectVoice();
    }
    
    // Voice Activity Detection loop
    function detectVoice() {
      if (!isInCall || isPlaying) return;
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(dataArray);
      
      // Calculate average volume
      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
      updateVisualizer(average);
      
      if (average > SILENCE_THRESHOLD) {
        // Voice detected
        if (!isRecording) {
          // Start recording
          isRecording = true;
          mediaRecorder.start();
          setStatus('Speaking...', 'speaking');
        }
        // Reset silence timer
        if (silenceTimer) clearTimeout(silenceTimer);
        silenceTimer = setTimeout(() => {
          // Silence detected after speaking - send audio
          if (isRecording && isInCall) {
            isRecording = false;
            mediaRecorder.stop();
          }
        }, SILENCE_DURATION);
      }
      
      if (isInCall && !isPlaying) {
        requestAnimationFrame(detectVoice);
      }
    }
    
    // Toggle call on button click
    callBtn.onclick = () => {
      if (isInCall) {
        endCall();
      } else {
        startCall();
      }
    };
  </script>
</body>
</html>
